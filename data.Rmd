# Data 

## Sources

The data comes from Touringplans.com, and the website collected all its data from the following three sources:     

1. From app users of [Touringplans.com]([https://touringplans.com/walt-disney-world/crowd-calendar#DataSets])     
The app records the time its users enter waiting lines and enjoy the facility. The difference between these two times is the actual waiting time.     

2. [Disney’s My Disney Experience app](https://disneyworld.disney.go.com/plan/my-disney-experience/?ef_id=CjwKCAjw5P2aBhAlEiwAAdY7dIkqzaELf-qklZ0q5Yby8vqX2Yxy38GD99jYgCp2JARCUI_u3nHwWxoCGRMQAvD_BwE:G:s&s_kwcid=AL!5060!3!601187705510!p!!g!!disney%20experience&CMP=KNC-FY23_WDW_TRA_DXF_W365_SCP_MYDX_MDX_Exact|G|5231013.RR.AM.01.01|MWNOQXO|BR|601187705510&keyword_id=aud-300113739056:kwd-2901498835|dc|disney%20experience|601187705510|p|5060:3|&gclid=CjwKCAjw5P2aBhAlEiwAAdY7dIkqzaELf-qklZ0q5Yby8vqX2Yxy38GD99jYgCp2JARCUI_u3nHwWxoCGRMQAvD_BwE)     
Disneyland estimates the waiting time based on the length of waiting lines. The estimated waiting time is posted on a sign at the entrance to attractions and shown on Disney's app.       

3. Observation from the staffs of [Touringplans.com]([https://touringplans.com/walt-disney-world/crowd-calendar#DataSets]) on sights. \ 
The staffs visit Disneyland and record their actual waiting time for each attraction.     

### Basic Information about Data

The data can be downloaded directly from the website for free in CSV format. In total, there are 5143775 time series records plus 95 rows of metadata cocntaining meta information about attraction. 
A CSV document downloaded contains all wait time data for a specific attraction. 
The wait time is recorded at different time intervals (every 1 ~ 10 minutes) for each day. 
Each CSV files consists of four columns, which are “date”, “datetime”, “SACTMIN”, and “SPOSTMIN”. 
Each columns has the type character, character, integer, and integer accordingly. 

### Issues & Design Choice:

After plotting the raw data (Section 3.3.2), we discovered the following problems: 

1. There are no data from April 2020 to October 2020, except August 2020. This is due to the COVID-19 outbreak, and the Magic Kingdom Park was closed. However, there is data for August, so we deemed that these data are recorded due to some error, and we dropped these data from our analysis.     

2. We also discovered that the “entities” data table assigned some attractions with the wrong themed land. To correctly group each attraction to the right land, we went to Disney’s official website to find a map and other related information.      

3. There are 41 attractions CSV files available to download, but not all these files contain valid data. Some files contain only _NA_ data for wait time, so after filtering out these files, there are only 25 files with valid wait time data.     

## Cleaning / transformation

After coarse filtering, our datasets have 25 CSV files. Below is an example of how our raw data look like for the attraction _Dumbo_:       
```{r}
df_temp <- read.csv("Data/data/Magic Kingdom/dumbo.csv")
head(df_temp)
```
       
Below is a list of all the data cleaning/transformation we have performed on raw data:
 
1. The “date” column is redundant because its values are all contained in the “datetime” column too, so we dropped the "date" column.       

2. “SACTMIN” has a lot of missing values, and we observed that when “SPOSTMIN” has missing data, its corresponding “SACTMIN” has a value and vice versa. Hence, we replaced all the missing values in “SPOSTMIN” with the values from “SACTMIN”.      

3. If both the “SACTMIN” and “SPOSTMIN” columns are _NA_, then it means that the row does not have valid wait time data for our analysis, so we drop the row.      

4. After combining the “SACTMIN” and “SPOSTMIN” columns, we renamed the old "SPOSTMIN” column to “Waiting Time” and dropped the “SACTMIN” column.      

5. In the new “Waiting Time” column, we also checked that if there are values less than 0. Since wait time cannot be negative, we dropped these negative values.      

Below is an example of how our cleaned data look like for the attraction Dumbo:     
```{r}
df_temp2 <- read.csv("Data/data/Magic Kingdom/xysong_python/dumbo.csv")
head(df_temp2)
```

Moreover, in our analysis of wait time based on the time of the day, we also converted the “datetime” column from character type to datetime using as.POSIXlt(). This will allow us to compare time easily. We assigned time before 12 PM to be the morning category, time between 12 PM and before 6 PM to be the afternoon category, and time after 6 PM to be the evening category.     

## Missing value analysis
```{r}
process_name <- function(csv) {
    return(gsub("  ", "", gsub(".csv", "", gsub("_", " ", csv))))
}

get_attraction_name <- function() {
    return(lapply(list.files("Data/data/Magic Kingdom/xysong_python"), process_name)) # nolint
}
# get_attraction_name() #nolint

read_raw <- function() {
    library(hash)
    filenames <- list.files("Data/data/Magic Kingdom/xysong_python") # nolint
    dict <- hash()
    for (csv in filenames) {
        dict[[process_name(csv)]] <- read.csv(sprintf("Data/data/Magic Kingdom/xysong_python/%s", csv)) # nolint
    }
    return(dict)
}
```

```{r}
# names <- get_attraction_name()
# # names[[4]]
# all_dsets <- read_raw()
# num_dsets <- length(all_dsets)
# class(head(all_dsets[["dumbo"]]$Datetime))
# # num_dsets
# # Configure start/end date
# start_date <- as.Date("2020-04-01")
# end_date <- as.Date("2020-10-01")

# dates <- c(
#     "2020-04-01 12:00:00",
#     "2020-05-01 12:00:00",
#     "2020-06-01 12:00:00",
#     "2020-07-01 12:00:00",
#     "2020-08-01 12:00:00",
#     "2020-09-01 12:00:00",
#     "2020-10-01 12:00:00"
# )
# # Complementary dataframe
# comp_df <- data.frame(
#     "X" = c(0, 1, 2, 3, 4, 5, 6),
#     "Datetime" = dates,
#     "Waiting.Time" = rep(0, 7)
# ) # nolint
# # Print out statistics
# outliers <- rep(0, num_dsets)
# for (i in 1:num_dsets) {
#     name <- names[[i]]
#     date_df <- as.Date(all_dsets[[name]]$Datetime, "%Y-%m-%d %H:%M:%S")
#     mask <- date_df > start_date & date_df < end_date
#     outliers[[i]] <- sum(mask)
#     all_dsets[[name]]$Waiting.Time[mask] <- rep(as.numeric(0.0), sum(mask))
#     # add complementary data frames
#     all_dsets[[name]] <- bind_rows(list(all_dsets[[name]], comp_df))
#     write.csv(all_dsets[[name]], sprintf("Data/data/cleaned/%s.csv", name))
# }

# num_vals <- rep(0, 25)
# for (i in 1:25) {
#     name <- names[[i]]
#     num_vals[[i]] <- nrow(all_dsets[[name]])
# }
# sum(num_vals)
# names[14]
```

```{r}
process_missing <- function() {
    missing_values <- read.csv("Data/data/entity_missing.csv")
    # missing_values$Open.Time
    missing_values <- missing_values[, c(2, 3, 4, 5)]
    # missing_values
    mask <- is.nan(missing_values$Duration)
    missing_values$Duration[mask] <- NA
    mask <- is.nan(missing_values$AWT_100)
    missing_values$AWT_100[mask] <- NA
    mask <- "nan" == missing_values$Open.Time
    missing_values$Open.Time[mask] <- as.numeric(NA)
    missing_values
    return(missing_values)
}
plot_missing_heatmap <- function(missing_values) {
    # missing_values
    missing_dsets <- missing_values %>%
        # rownames_to_column("id") %>%
        gather(key, value, -c(Official.Name)) %>%
        mutate(missing = ifelse(is.na(value), "yes", "no"))
    library(ggeasy)
    g <- ggplot(missing_dsets, aes(x = key, y = Official.Name, fill = missing)) +
        geom_tile(color = "white") +
        ggtitle("Missing Patterns for All Attractions") +
        ggeasy::easy_center_title() +
        ylab("Attractions") +
        xlab("Attributes") +
        scale_fill_viridis_d() + # discrete scale
        theme_bw()
    return(g)
}
```
```{r}
# Credit: the following code is the source code from redav library
# We copy that here because we are not able to install the package due to R version issue.
# Link: https://rdrr.io/github/jtr13/redav/src/R/plot_missing.R
# library(redav)
plot_missing <- function(x, percent = TRUE) {
    na_count_all <- data.frame(is.na(x)) %>%
        dplyr::group_by_all() %>%
        dplyr::count(name = "count", sort = TRUE) %>%
        dplyr::ungroup() %>%
        tibble::rownames_to_column("pattern")

    na_count_all <- na_count_all %>%
        dplyr::mutate(pattern = factor(.data$pattern, levels = nrow(na_count_all):1))

    # count the number of columns with missing values; will be used later to determine if there's a "none missing" pattern
    na_count_all <- na_count_all %>%
        dplyr::rowwise() %>%
        dplyr::mutate(num_missing_cols = sum(dplyr::c_across(where(is.logical))))

    # data frame for missing patterns bar chart
    na_count_by_pattern <- na_count_all[, c("pattern", "count", "num_missing_cols")]
    na_count_by_pattern$none_missing <- ifelse(na_count_by_pattern$num_missing_cols == 0, TRUE, FALSE)

    # data frame for missing by column bar chart
    na_count_by_column <- data.frame(is.na(x)) %>%
        colSums() %>%
        sort(decreasing = TRUE) %>%
        tibble::enframe(name = "var", value = "count")

    # tidy and sort na_count_all by column counts
    na_count_all_tidy <- na_count_all %>%
        tidyr::pivot_longer(where(is.logical), names_to = "variable") %>%
        dplyr::mutate(variable = factor(.data$variable, levels = na_count_by_column$var)) %>%
        dplyr::mutate(none_missing = ifelse(.data$num_missing_cols == 0, TRUE, FALSE))

    # main plot
    main_plot <- ggplot2::ggplot(na_count_all_tidy, ggplot2::aes(.data$variable, .data$pattern, fill = factor(.data$value), alpha = .data$none_missing)) +
        ggplot2::geom_tile(color = "white") +
        ggplot2::scale_fill_manual(values = c("grey70", "mediumpurple")) +
        ggplot2::scale_alpha_manual(values = c(.7, 1)) +
        ggplot2::ylab("missing pattern") +
        ggplot2::guides(fill = "none", alpha = "none") +
        ggplot2::theme_classic(12)

    # check for "none missing" pattern
    none_missing_pattern <- na_count_by_pattern %>%
        dplyr::filter(.data$none_missing) %>%
        dplyr::pull(.data$pattern)

    if (length(none_missing_pattern) > 0) {
        main_plot <- main_plot +
            ggplot2::annotate("text",
                x = (ncol(na_count_all) - 2) / 2,
                y = nrow(na_count_all) + 1 - as.numeric(as.character(none_missing_pattern)),
                label = "complete cases"
            )
    }

    # margin plots

    denom <- ifelse(percent, nrow(x) / 100, 1)

    missing_by_column_plot <- ggplot2::ggplot(na_count_by_column, ggplot2::aes(forcats::fct_inorder(.data$var), .data$count / denom)) +
        ggplot2::geom_col(fill = "cornflowerblue", alpha = .7) +
        ggplot2::scale_y_continuous(expand = c(0, 0), n.breaks = 3) +
        ggplot2::xlab("") +
        ggplot2::ylab(ifelse(percent, "% rows \n missing:", "num rows \n missing:")) +
        ggplot2::theme_linedraw(12) +
        ggplot2::theme(
            panel.grid.major.x = ggplot2::element_blank(),
            panel.grid.minor.x = ggplot2::element_blank()
        )

    missing_by_pattern_plot <-
        ggplot2::ggplot(na_count_by_pattern, ggplot2::aes(.data$pattern, .data$count / denom, alpha = .data$none_missing)) +
        ggplot2::geom_col(fill = "cornflowerblue") +
        ggplot2::coord_flip() +
        ggplot2::scale_y_continuous(expand = c(0, 0), n.breaks = 3) +
        ggplot2::scale_alpha_manual(values = c(.7, 1)) +
        ggplot2::xlab("") +
        ggplot2::ylab(ifelse(percent, "% rows", "row count")) +
        ggplot2::guides(alpha = "none") +
        ggplot2::theme_linedraw(12) +
        ggplot2::theme(
            panel.grid.major.y = ggplot2::element_blank(),
            panel.grid.minor.y = ggplot2::element_blank()
        )

    if (percent) {
        missing_by_column_plot <- missing_by_column_plot +
            ggplot2::scale_y_continuous(
                expand = c(0, 0), n.breaks = 5,
                limits = c(0, 100)
            )
        missing_by_pattern_plot <- missing_by_pattern_plot +
            ggplot2::scale_y_continuous(
                expand = c(0, 0), n.breaks = 5,
                limits = c(0, 100)
            )
    }

    missing_by_column_plot + patchwork::plot_spacer() +
        main_plot + missing_by_pattern_plot +
        patchwork::plot_layout(widths = c(4, 1), heights = c(1, 4))
}
```

### Missing Metadata

```{r}
library(gridExtra)
library(ggplot2)
library(ggeasy)
library(dplyr)
library(lubridate)
library(tidyverse)
# process_missing()
g0 <- plot_missing_heatmap(process_missing())
g0
g1 <- plot_missing(process_missing(), percent = FALSE)
g1
# process_missing()
# grid.arrange(g1, g0, nrow = 2)
```

From the above chart, we can see that there are missing data values for all the three variables. These three variables are some general information about each attraction, and we observe that if one variable has missing data, then the other two variables tend to be missing too, only one exception for attraction “enchanted tiki rm”. We dropped the missing data for our analysis. Since they do not have a strong relationship with analyzing the wait time trend.     

### Missing Time Series Data

```{r}
library(dplyr)
raw_df <- read_raw()
# dumbo <- raw_df[["dumbo"]]

df <- bind_rows(lapply(get_attraction_name(), function(i) raw_df[[i]]))

plot_bar_missing <- function(df, start, end, year) {
    df <- df %>%
        dplyr::mutate(Datetime = as.Date(Datetime, "%Y-%m-%d %H:%M:%S")) %>%
        dplyr::mutate(month = lubridate::floor_date(Datetime, "month")) %>%
        dplyr::group_by(month) %>%
        dplyr::summarise(freq = n()) %>%
        dplyr::filter(month >= start & month < end)

    g1 <- df %>% ggplot(aes(x = month, y = freq)) + # nolint
        geom_bar(stat = "identity", fill = "#EFBEB7", alpha = 0.8) +
        xlab("Date") +
        ylab("Number of records") +
        # scale_color_manual()+
        scale_x_date(date_labels = "%b %Y", date_breaks = "4 months", guide = guide_axis(angle = 45)) + # nolint
        ggtitle(sprintf("# Time Series Records from %s", year)) +
        ggeasy::easy_center_title()
    # scale_x_discrete(guide = guide_axis(angle = 45)) +
    # theme(panel.grid.major.x = element_blank())
    return(g1)
}

identify_abnormal <- function(g, start, end, text_y) {
    g <- g + annotate("rect", xmin = start, xmax = end, ymin = -Inf, ymax = Inf, fill = "lightblue", alpha = 0.3) # nolint
    # Append text
    g <- g + annotate("text", x = as.Date("2020-03-01"), y = text_y, label = "COVID OUTBREAK\n  MISSING DATA", color = "Black", hjust = 0) # nolint
    return(g)
}

start <- as.Date("2015-01-01", "%Y-%m-%d")
mid1 <- as.Date("2017-04-01", "%Y-%m-%d")
mid2 <- as.Date("2019-08-01", "%Y-%m-%d")
end <- as.Date("2022-01-01", "%Y-%m-%d")
g1 <- plot_bar_missing(df, start, mid1, "2015 Jan to 2017 Mar")
g2 <- plot_bar_missing(df, mid1, mid2, "2017 Apr to 2019 Jul")
g3 <- plot_bar_missing(df, mid2, end, "2019 Aug to 2021 Dec")
# g_all <- plot_bar_missing(df, start, end, "2015 Jan to 2021 Dec")
missing_start <- as.Date("2020-03-15")
missing_end <- as.Date("2020-10-15")
g3 <- identify_abnormal(g3, missing_start, missing_end, 80000)
# grid.arrange(g1 + coord_flip(), g2 + coord_flip(), g3 + coord_flip(), nrow = 1)
grid.arrange(g1, g2, g3, nrow = 3)
# g_all + coord_flip()
# g1
```