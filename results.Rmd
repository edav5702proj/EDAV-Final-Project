# Results

<script src="https://d3js.org/d3.v7.min.js"></script>

<!-- Zoom in -->
<div id="myModal" class="modal">

  <!-- The Close Button -->
  <span class="close">&times;</span>

  <!-- Modal Content (The Image) -->
  <img class="modal-content" id="img01">

  <!-- Modal Caption (Image Text) -->
  <div id="caption"></div>
</div>

## Assumption

```{r, out.extra='id:"avg_abnormal"'}
process_name <- function(csv) {
    return(gsub("  ", "", gsub(".csv", "", gsub("_", " ", csv))))
}

get_attraction_name <- function() {
    return(lapply(list.files("Data/data/Magic Kingdom/xysong_python"), process_name)) # nolint
}
# get_attraction_name() #nolint


read_all <- function() {
    library(hash)
    # filenames <- list.files("Data/data/Magic Kingdom/xysong_python") # nolint
    filenames <- list.files("Data/data/cleaned/") # nolint
    dict <- hash()
    for (csv in filenames) {
        # dict[[process_name(csv)]] <- read.csv(sprintf("Data/data/Magic Kingdom/xysong_python/%s", csv)) # nolint
        dict[[process_name(csv)]] <- read.csv(sprintf("Data/data/cleaned/%s", csv)) # nolint
    }
    return(dict)
}
```
As introduced in the data cleaning section, our exploratory analysis is heavily based on 
the _waiting\_time_ statistics of attractions in the Walt Disneyland collected from thrid-party 
organization. Therefore, it is extremely crucial 
to examine the validity and reliability of the _assumptions_ that our analysis will rely on and 
think about any _inductive biases_ that we implicitly impose in the analysis. Specifically, there are 
two important aspects that we want to research on:

- Assumption 1: the dataset is valid and reliable (i.e. no internal conflicts)
- Assumption 2: waiting time statistic is a representative metric for analysis


### Assumption 1
Unlike most other groups whose datasets come from official sources including government websites 
and database where verifications are conducted, the dataset we used is collected from a __thrid 
party organization__ [Touringplans.com]([https://touringplans.com/walt-disney-world/crowd-calendar#DataSets]).
Therefore, validation of dataset is necessary and important. We performed our validation by identifying 
internal conflicts of datasets and compare our preliminary analysis with reports from the official (i.e. Disneyland).

The first simple task we tried to validiate our dataset is to predict top seven attractions according to 
their popularity. In our dataset, we computed the _average waiting time_ for each attraction (denoted by _AWT_ in the plot) and 
made usage of the _average\_wait\_every\_hundred_ statistic (i.e. denoted by _AWT\_100_ in the plot) to do the prediction. 
Note that _AWT\_100_ represents the average waiting time for every hundred people. Therefore, attractions that are 
popular should be those with high _AWT_ but low _AWT\_100_. 
```{r}
library(ggplot2)
library(ggeasy)
library(dplyr)
library(lubridate)
library(tidyverse)
# Setup scripts
all_dsets <- read_all()
# mean(all_dsets[["dumbo"]]$Waiting.Time)
```
```{r}
# Read avg_wait_100 files
avg_wait_100 <- read.csv("Data/data/name_avg_wait.csv")
get_avg_df <- function(df) {
    return(mean(df$Waiting.Time))
}
# 18 out of 25 rows have correponding no-NAs values
avg_wait <- rep(0, 18)
for (i in 1:18) {
    avg_wait[[i]] <- mean(all_dsets[[avg_wait_100$name[[i]]]]$Waiting.Time)
}
avg_wait_100$avg <- avg_wait
avg_wait_100$popular <- rep("Other Attractions", 18)
# Manually insert popular
for (i in c(1, 2, 5, 6, 7, 8, 17)) {
    avg_wait_100$popular[[i]] <- "Top 7 Popular Attractions"
}
# avg_wait_100$popular
# avg_wait_100
# Plot
g0 <- ggplot(avg_wait_100, aes(avg_wait_time, avg, color = popular)) +
    geom_point(alpha = 0.4, size = 4) +
    labs(x = "AWT_100 (min)", y = "AWT (min)") + # nolint

    ggtitle("AWT vs. AWT_100") +
    ggeasy::easy_center_title()
g0
```

According to this reasoning, we identified that the top 7 most popular attractions from the 
scatter plot above: _Seven Dwarfs Mine Train_, _Space Mountain_, _Jungle Cruise_, _Splash Mountain_
, _Big Thunder Mountain Railroad_, _Pirates of Caribbean_, and _Haunted Mansions_. Based on the report of 
most popular attractions by [magicguides.com](https://magicguides.com/best-magic-kingdom-rides/) and the 
introduction from [Disneyland Officials](https://disneyworld.disney.go.com/destinations/magic-kingdom/?ef_id=CjwKCAiAheacBhB8EiwAItVO2w0FdC8qLzR3mnfUO_KKMy3L1hkZoT3LEHDEm9hiGW9Keu9XNjT1JhoC0t0QAvD_BwE:G:s&s_kwcid=AL!5060!3!590827088345!e!!g!!magic%20kingdom%20theme%20park&CMP=KNC-FY23_WDW_TRA_DXF_W365_TKT_TCKC_Tickets_EVRGRN_MKParks-Exact|G|5231213.RR.AM.01.01|M5JMF0M|BR|590827088345&keyword_id=kwd-1416849944|dc|magic%20kingdom%20theme%20park|590827088345|e|5060:3|&gclid=CjwKCAiAheacBhB8EiwAItVO2w0FdC8qLzR3mnfUO_KKMy3L1hkZoT3LEHDEm9hiGW9Keu9XNjT1JhoC0t0QAvD_BwE) 
the most popular 7 attractions are: _Big Thunder Mountain Railroad_, _Jungle Cruise_
, _Splash Mountain_, _Peter Pan's Flight_, _Haunted Mansions_, _Pirates of Caribbean_, and _Seven Dwarfs Mine Train_. 
Our prediction results matched with most of their analysis (6/7), and we can improve our confidence about the 
reliability of the source data from this small prediction task. In addition, there is no internal conflict in our dataset 
because they are all time series data for different attractions.

### Assumption 2

By calculating and plotting the waiting time for each attraction, 
we identified that _average waiting time_ itself is not a good indicator for 
popularity of the attraction. Note that we observe that the _average waiting time_ is not always higher for 
popular attractions identified in previous section. Thus, we should not solely leverage on that when analyzing the popularity of attractions. However, 
with the power of time series data, it is powerful when analyzing trend and designing visiting plans.

```{r}
num_dsets <- length(all_dsets)
names <- get_attraction_name()
avg_wait <- rep(0, num_dsets)
for (i in 1:num_dsets) {
    avg_wait[[i]] <- mean(all_dsets[[names[[i]]]]$Waiting.Time)
}
# avg_wait
df <- data.frame(
    name = c(unlist(names)),
    avg_wait = c(unlist(avg_wait)),
    popular = c(unlist(rep("Other Attractions", 25)))
)
for (i in c(1, 2, 5, 6, 7, 8, 17)) {
    df$popular[[i]] <- "Top 7 Popular Attractions"
}

g1 <- df %>% ggplot(aes(x = fct_reorder(name, avg_wait, .desc = TRUE), y = avg_wait, fill = popular)) + # nolint
    geom_bar(stat = "identity", alpha = 0.8) +
    ggtitle("Average Waiting Time for Each Attraction") +
    xlab("Attractions") +
    ylab("AWT") +
    # scale_color_manual()+
    ggtitle("AWT vs. Attraction") +
    ggeasy::easy_center_title() +
    scale_x_discrete(guide = guide_axis(angle = 45)) +
    theme(panel.grid.major.x = element_blank())
g1
```

## General Pattern Analysis - Macro-Level
With confidence of dataset validity, we first analyze the pattern of waiting time of each attraction 
spanning from _2015-01-01_ to _2022-01-01_, by which we can identify the peak season of Walt Disneyland. Note that for this section, 
we are doing macro-scale analysis, implying we will focus on the _average waiting time_ for each month for each attraction. 

### Secular Trends

To identify secular trend, we computed the _average waiting time_ for each month for all attractions and then made the following time series plot. 
Here is the main observations:

- From _2015_ to _2019_, there is a general trend of increasing waiting time.\
Explanation: as Disneyland became more famous, there are more tourists but the attractions remain unchanged, which result in an increasing of waiting time.
- From about _2019_ to _2020_, there is a huge decreasing in terms of waiting time.\
Explanation: this corresponds to the outbreak of COVID-19 in the United States, which result in the temporary close of Disneyland and the huge decreasing of number of tourists even after reopening.
- Starting from _2020_, there is a general trend of increasing waiting time\
Explanation: this corresponds to the fact that people are back to normal life from COVID disruption.
- There is an obvious abnormality in the plot (_2020-04-01_ to _2020-10-01_), where the waiting times are all zeros, which correpond to the 
closure of Disneyland. (Note that there is a design choice for plotting; see Data Cleaning section for details)

**Note**: According to Disneyland's Officials, Disneyland was closed during COVID-19 outbreaks
```{r}
# source("Utility/utils.R")

all_dsets <- read_all()
dumbo <- all_dsets[["dumbo"]]
# class(dumbo)
# Elementary statistics
# head(dumbo)
# Get all datasets
df_all <- bind_rows(lapply(get_attraction_name(), function(i) all_dsets[[i]]))
# nrow(df_all) #nolint

# Example
# head(dsets) #nolint
group_by <- function(df) {
    # Process dataframe
    dsets <- df %>%
        dplyr::mutate(Datetime = as.Date(Datetime, "%Y-%m-%d %H:%M:%S")) %>%
        dplyr::mutate(month = lubridate::floor_date(Datetime, "month")) %>%
        dplyr::group_by(month) %>%
        dplyr::summarise(avg = sum(Waiting.Time) / n())
    return(dsets)
}

plot_time_series <- function(dsets, name) { # Plot
    g <- ggplot(dsets, aes(month, avg), type = "l") +
        geom_line(color = "black") +
        # geom_line(color = "#F3CC64") +
        geom_point(color = "deeppink", alpha = 0.4) +
        geom_smooth(method = "loess", span = .5, se = FALSE) +
        scale_x_date(date_labels = "%b %Y", date_breaks = "6 months", guide = guide_axis(angle = 45)) + # nolint
        xlab("Month") +
        ylab("Average Waiting Time (minutes)") +
        ggtitle(sprintf("%s: Average Waiting Time (By Month)", name)) +
        ggeasy::easy_center_title()
    return(g)
}
identify_abnormal <- function(g, start, end, text_y) {
    g <- g + annotate("rect", xmin = start, xmax = end, ymin = -Inf, ymax = Inf, fill = "lightblue", alpha = 0.3) # nolint
    # Append text
    g <- g + annotate("text", x = end + 10, y = text_y * (4 / 5), label = "COVID \nOUTBREAK", color = "#393E8F", hjust = 0) # nolint
    return(g)
}

plot_in_one_shot <- function(df, name) {
    grouped_dsets <- group_by(df)
    g <- plot_time_series(grouped_dsets, name)
    start <- as.Date("2020-01-01")
    end <- as.Date("2020-12-01")
    g <- identify_abnormal(g, start, end, max(grouped_dsets$avg))
    return(g)
}
# nrow(df_all) #nolint
g2 <- plot_in_one_shot(df_all, "All Attractions")
g2
```

Below are the time series plot for the average waiting time changing pattern for each attraction in Disneyland. **Click on the plots to zoom in**. 
Through this juxtaposition, we can easily observed that the four trends and abnormalites that 
we identified eariler is universal across all attractions, and we do not subject to _Simpson's Paradox_.

<!-- :::{#abnormal_plot} -->
```{r, fig.show="hold", out.width="20%", out.extra='class="abnormal"'}
all_plot <- list()
names <- get_attraction_name()
# length(names)
# names
for (i in 1:25) {
    name <- names[[i]]
    all_plot[[i]] <- plot_in_one_shot(all_dsets[[name]], name)
}
for (g in all_plot) {
    print(g)
}
```
<!-- ::: -->


### Identify cyclical patterns

:::{#facet}
```{r, fig.show="hold", out.width="50%"}
dumbo <- all_dsets[["dumbo"]]
# dumbo
head(dumbo)
# sum(dumbo$Waiting.Time) / nrow(dumbo)
group_by_date <- function(df) {
    # Process dataframe
    dsets <- df %>%
        dplyr::mutate(Datetime = as.Date(Datetime, "%Y-%m-%d %H:%M:%S")) %>%
        dplyr::group_by(Datetime) %>%
        dplyr::summarise(avg = sum(Waiting.Time) / n()) %>%
        dplyr::mutate(yr = year(Datetime))
    return(dsets)
}
dset <- group_by_date(dumbo)
head(dset)
g <- ggplot(dset, aes(as.Date(format(Datetime, format = "%m-%d"), "%m-%d"), avg)) + # nolint
    geom_line(color = "grey30") +
    geom_point(size = 0.1) +
    scale_x_date(date_labels = "%b", date_breaks = "1 months", guide = guide_axis(angle = 45)) + # nolint
    facet_grid(yr ~ ., scale = "free_y") +
    geom_smooth(se = FALSE)
g
print(head(dset, 100), n = 100)
as.character(as.Date("2020/01/01"))
# grid.arrange(g,g, ncol=2) #nolint
g
g
g
head(dset, 100)
```
:::

```{r}
# Check duration
df <- read.csv("Data/data/name_duration.csv")
df
avg_wait <- rep(0, 18)
for (i in 1:18) {
    avg_wait[[i]] <- mean(all_dsets[[df$name[[i]]]]$Waiting.Time)
}
df$avg <- avg_wait
write.csv(df, "Data/data/name_duration_avg.csv", row.names = FALSE)
# Check writing csv
df <- read.csv("Data/data/name_duration_avg.csv")
```
<script src="zoom.js"></script>

## General Pattern Analysis - Micro-Level



